{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "c5cb62ac-8e88-43e6-bce9-da20fabf38ff",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "987c7c95a0c7dc71b3d85e154cc3a9be",
     "grade": false,
     "grade_id": "cell-6ebb8bd2f22353d3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Question A4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "5c8f824c",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "17d770ae590711dc06f03d150970a3f1",
     "grade": false,
     "grade_id": "cell-e34b0415c38ebac4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In this section, we will understand the utility of such a neural network in real world scenarios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "fb9411ad-2324-400e-852e-ff5c0ca716f0",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "287259c58079728b66dae175c6082400",
     "grade": false,
     "grade_id": "cell-4f74b97314b65ea1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "#### Please use the real record data named ‘record.wav’  as a test sample. Preprocess the data using the provided preprocessing script (data_preprocess.ipynb) and prepare the dataset.\n",
    "Do a model prediction on the sample test dataset and obtain the predicted label using a threshold of 0.5. The model used is the optimized pretrained model using the selected optimal batch size and optimal number of neurons.\n",
    "Find the most important features on the model prediction for the test sample using SHAP. Plot the local feature importance with a force plot and explain your observations.  (Refer to the documentation and these three useful references:\n",
    "https://christophm.github.io/interpretable-ml-book/shap.html#examples-5,\n",
    "https://towardsdatascience.com/deep-learning-model-interpretation-using-shap-a21786e91d16,  \n",
    "https://medium.com/mlearning-ai/shap-force-plots-for-classification-d30be430e195)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "981c85ca-9a14-4d0a-b44d-814f02c0f8e1",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "30c3b93836aad148380e15933e7dd786",
     "grade": false,
     "grade_id": "cell-b8a265bf37e3b271",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "1. Firstly, we import relevant libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "58c50f4f",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8f6af6091e2832c850b00e735d1cff11",
     "grade": false,
     "grade_id": "libraries",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from scipy.io import wavfile as wav\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n",
    "from common_utils import set_seed\n",
    "\n",
    "# setting seed\n",
    "set_seed()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "d3444c83",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d796a3a33dd56bd5afb55de45b642449",
     "grade": false,
     "grade_id": "cell-293c9e85ad81d29a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "To reduce repeated code, place your\n",
    "network (MLP defined in QA1)\n",
    "torch datasets (CustomDataset defined in QA1)\n",
    "loss function (loss_fn defined in QA1)\n",
    "in a separate file called common_utils.py\n",
    "\n",
    "Import them into this file. You will not be repenalised for any error in QA1 here as the code in QA1 will not be remarked.\n",
    "\n",
    "The following code cell will not be marked.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "id": "72e8e840",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0c623c0417cb6065d1bbb049f211cf1c",
     "grade": false,
     "grade_id": "cell-29dace0045a28b89",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "from common_utils import MLP, CustomDataset, loss_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "b12f3ced-a6a1-4628-a409-1ca7bdfd1cfa",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8dbab024c3394801484199efdbbdb269",
     "grade": true,
     "grade_id": "corrected",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "18fd5d5e",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7da5539e4fe97549a11c7d61be647167",
     "grade": false,
     "grade_id": "cell-1c5bf554b8f89a3d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "2. Install and import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "id": "e49be1fc",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f58a0104d88201d0af7de9fc3a6ca035",
     "grade": false,
     "grade_id": "import_shap",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: shap in d:\\program files\\python310\\lib\\site-packages (0.45.0)\n",
      "Requirement already satisfied: numba in d:\\program files\\python310\\lib\\site-packages (from shap) (0.59.0)\n",
      "Requirement already satisfied: cloudpickle in d:\\program files\\python310\\lib\\site-packages (from shap) (3.0.0)\n",
      "Requirement already satisfied: tqdm>=4.27.0 in d:\\program files\\python310\\lib\\site-packages (from shap) (4.65.0)\n",
      "Requirement already satisfied: scikit-learn in d:\\program files\\python310\\lib\\site-packages (from shap) (1.2.2)\n",
      "Requirement already satisfied: scipy in d:\\program files\\python310\\lib\\site-packages (from shap) (1.10.1)\n",
      "Requirement already satisfied: packaging>20.9 in d:\\program files\\python310\\lib\\site-packages (from shap) (23.1)\n",
      "Requirement already satisfied: numpy in d:\\program files\\python310\\lib\\site-packages (from shap) (1.24.3)\n",
      "Requirement already satisfied: slicer==0.0.7 in d:\\program files\\python310\\lib\\site-packages (from shap) (0.0.7)\n",
      "Requirement already satisfied: pandas in d:\\program files\\python310\\lib\\site-packages (from shap) (2.0.1)\n",
      "Requirement already satisfied: colorama in d:\\program files\\python310\\lib\\site-packages (from tqdm>=4.27.0->shap) (0.4.6)\n",
      "Requirement already satisfied: llvmlite<0.43,>=0.42.0dev0 in d:\\program files\\python310\\lib\\site-packages (from numba->shap) (0.42.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\program files\\python310\\lib\\site-packages (from pandas->shap) (2.8.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in d:\\program files\\python310\\lib\\site-packages (from pandas->shap) (2023.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\program files\\python310\\lib\\site-packages (from pandas->shap) (2023.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in d:\\program files\\python310\\lib\\site-packages (from scikit-learn->shap) (3.1.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in d:\\program files\\python310\\lib\\site-packages (from scikit-learn->shap) (1.2.0)\n",
      "Requirement already satisfied: six>=1.5 in d:\\program files\\python310\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->shap) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "d:\\Program Files\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "!pip install shap\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "ef497933-2108-4aa5-8ec8-5729214cb1cd",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4cf4df5a01325e8ea1f585dcfc81b01b",
     "grade": true,
     "grade_id": "import_shap_correct",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "c5fde60a",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b8877105a451813ab23b45e9a180bc36",
     "grade": false,
     "grade_id": "cell-82dd5a271bf5af4b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "3. Read the csv data preprocessed from 'record.wav', using variable name 'df', and fill the size of 'df' in 'size_row' and 'size_column'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "id": "81a54d47",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c35348846173e5c042d78be10546ae86",
     "grade": false,
     "grade_id": "cell-01d5f7ef70e69e09",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "df = 0\n",
    "size_row = 0\n",
    "size_column = 0\n",
    "# YOUR CODE HERE\n",
    "df = pd.read_csv('new_record.csv')\n",
    "size_row = df.shape[0]\n",
    "size_column = df.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "571b0b06-1750-4228-88af-67d8c52035dc",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4d137f7e21ec2ea9ad7a57f4411b513a",
     "grade": true,
     "grade_id": "cell-01d5f7ef70e69e0988",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "558aa470-6d7e-454c-9cda-9ad881d58c53",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d3d13eea6f0ed0d345e10f33dd3a26da",
     "grade": false,
     "grade_id": "cell-7096e580d10284df",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    " 4.  Preprocess to obtain the test data, save the test data as numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "id": "8c77bd18-c546-473e-8c2f-643b4281d9ba",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b19be33055efd5fc5d562a9c671b6eb2",
     "grade": false,
     "grade_id": "cell-b1e392e8ecab207a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def preprocess(X_train, df):\n",
    "    \"\"\"preprocess your dataset to obtain your test dataset, remember to remove the 'filename' as Q1\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    # drop useless columns for df\n",
    "    columns_to_drop = ['filename']\n",
    "    df = df.drop(columns=columns_to_drop)\n",
    "\n",
    "    # scale the data\n",
    "    scaler = preprocessing.StandardScaler()\n",
    "\n",
    "    scaler.fit(X_train)\n",
    "    X_test_scaled_eg = scaler.transform(df)\n",
    "\n",
    "    return X_test_scaled_eg\n",
    "\n",
    "from common_utils import split_dataset\n",
    "\n",
    "# preprocess old training and testing data\n",
    "old_df = pd.read_csv('simplified.csv')\n",
    "old_df['label'] = old_df['filename'].str.split('_').str[-2]\n",
    "columns_to_drop = ['filename', 'label']\n",
    "\n",
    "# perform data splitting first\n",
    "X_train, y_train, X_test, y_test = split_dataset(old_df, columns_to_drop=columns_to_drop, test_size=0.25, random_state=100)\n",
    "\n",
    "X_test_scaled_eg = preprocess(X_train, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "e49ee8a7-d9b2-499d-8394-d6cb86f4cb60",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b0c0b2a92c7d501f1ac652e11f948461",
     "grade": true,
     "grade_id": "cell-fbe8ba077fb74598",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "b6756ab6-92e0-4a5e-b4b9-aebe009f5480",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "96d2e019d65c49ba15b3089c2184f021",
     "grade": false,
     "grade_id": "cell-48b4edbfec330f39",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "5. Do a model prediction on the sample test dataset and obtain the predicted label using a threshold of 0.5. The model used is the optimized pretrained model using the selected optimal batch size and optimal number of neurons. Note: Please define the variable of your final predicted label as 'pred_label'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "id": "8fa3afdf-eed6-47b9-9acc-bc2304c46ec3",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "276ec9575db4ca701823a459809ea810",
     "grade": true,
     "grade_id": "cell-e83cb49660edc2b7",
     "locked": false,
     "points": 4,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "MLP.__init__() missing 3 required positional arguments: 'no_features', 'no_hidden', and 'no_labels'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m lr \u001b[39m=\u001b[39m \u001b[39m0.001\u001b[39m  \u001b[39m# learning rate\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[39m# initialize model\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m model \u001b[39m=\u001b[39m MLP()\n\u001b[0;32m     13\u001b[0m para_list \u001b[39m=\u001b[39m []\n\u001b[0;32m     14\u001b[0m optimal_combination\u001b[39m.\u001b[39minsert(\u001b[39m0\u001b[39m, no_features)\n",
      "\u001b[1;31mTypeError\u001b[0m: MLP.__init__() missing 3 required positional arguments: 'no_features', 'no_hidden', and 'no_labels'"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "# set path\n",
    "model_path = 'model.pth'\n",
    "\n",
    "# initialize model\n",
    "optimal_combination = [256, 256, 128]\n",
    "no_features = 77 # feature number\n",
    "no_labels = 1  # output label number\n",
    "lr = 0.001  # learning rate\n",
    "\n",
    "# initialize model\n",
    "model = MLP()\n",
    "para_list = []\n",
    "optimal_combination.insert(0, no_features)\n",
    "optimal_combination.append(no_labels)\n",
    "for i in range(len(optimal_combination) - 1):\n",
    "    para_list.append((optimal_combination[i], optimal_combination[i + 1]))\n",
    "for j in range(len(para_list)):\n",
    "    if j == len(para_list) - 1:\n",
    "        model.add_layer(f\"Linear{j}\", nn.Linear(*para_list[j]))\n",
    "        model.add_layer(f\"Sigmoid{j}\", nn.Sigmoid())\n",
    "    else:\n",
    "        model.add_layer(f\"Linear{j}\", nn.Linear(*para_list[j]))\n",
    "        model.add_layer(f\"ReLU{j}\", nn.ReLU())\n",
    "        model.add_layer(f\"Dropout{j}\", nn.Dropout(0.2))\n",
    "\n",
    "# load model\n",
    "model.load_state_dict(torch.load(\"model.pth\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "da2fc2cc-b89f-4fc3-af16-e30b4e5315a3",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "704df2be8fbd85ba163a89cd2e0431f0",
     "grade": true,
     "grade_id": "predict_value",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "baab6e4d-4e8b-4358-a68d-682f60db4a06",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "eac3438866b5ebd40f5fb20a676059bd",
     "grade": false,
     "grade_id": "cell-896f18b6b0b948ea",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "6. Find the most important features on the model prediction for your test sample using SHAP. Create an instance of the DeepSHAP which is called DeepExplainer using traianing dataset: https://shap-lrjball.readthedocs.io/en/latest/generated/shap.DeepExplainer.html.\n",
    "\n",
    "Plot the local feature importance with a force plot and explain your observations.  (Refer to the documentation and these three useful references:\n",
    "https://christophm.github.io/interpretable-ml-book/shap.html#examples-5,\n",
    "https://towardsdatascience.com/deep-learning-model-interpretation-using-shap-a21786e91d16,  \n",
    "https://medium.com/mlearning-ai/shap-force-plots-for-classification-d30be430e195)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "081aa567-cd92-4749-93fd-fc6608a1f6ae",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "db46b1b26fd45359768421987104ac3e",
     "grade": true,
     "grade_id": "importance_weight",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Fit the explainer on a subset of the data (you can try all but then gets slower)\n",
    "Return approximate SHAP values for the model applied to the data given by X.\n",
    "Plot the local feature importance with a force plot and explain your observations.\n",
    "'''\n",
    "# YOUR CODE HERE"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
