{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pp6KAX1UXqaK"
   },
   "source": [
    "# Question B4 (10 marks)\n",
    "\n",
    "Model degradation is a common issue faced when deploying machine learning models (including neural networks) in the real world. New data points could exhibit a different pattern from older data points due to factors such as changes in government policy or market sentiments. For instance, housing prices in Singapore have been increasing and the Singapore government has introduced 3 rounds of cooling measures over the past years (16 December 2021, 30 September 2022, 27 April 2023).\n",
    "\n",
    "In such situations, the distribution of the new data points could differ from the original data distribution which the models were trained on. Recall that machine learning models often work with the assumption that the test distribution should be similar to train distribution. When this assumption is violated, model performance will be adversely impacted.  In the last part of this assignment, we will investigate to what extent model degradation has occurred.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WsfKoCAMj9uo"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rjdf67uIarDX"
   },
   "source": [
    "Your co-investigators used a linear regression model to rapidly test out several combinations of train/test splits and shared with you their findings in a brief report attached in Appendix A below. You wish to investigate whether your deep learning model corroborates with their findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "M3-BW2LW4Icq",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: alibi-detect in d:\\program files\\python310\\lib\\site-packages (0.11.5)\n",
      "Requirement already satisfied: scipy<2.0.0,>=1.3.0 in d:\\program files\\python310\\lib\\site-packages (from alibi-detect) (1.10.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.28.1 in d:\\program files\\python310\\lib\\site-packages (from alibi-detect) (4.65.0)\n",
      "Requirement already satisfied: toml<1.0.0,>=0.10.1 in d:\\program files\\python310\\lib\\site-packages (from alibi-detect) (0.10.2)\n",
      "Requirement already satisfied: catalogue<3.0.0,>=2.0.0 in d:\\program files\\python310\\lib\\site-packages (from alibi-detect) (2.0.10)\n",
      "Requirement already satisfied: scikit-learn<2.0.0,>=0.20.2 in d:\\program files\\python310\\lib\\site-packages (from alibi-detect) (1.4.1.post1)\n",
      "Requirement already satisfied: numba!=0.54.0,<0.59.0,>=0.50.0 in d:\\program files\\python310\\lib\\site-packages (from alibi-detect) (0.58.1)\n",
      "Requirement already satisfied: dill<0.4.0,>=0.3.0 in d:\\program files\\python310\\lib\\site-packages (from alibi-detect) (0.3.7)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.0.0 in d:\\program files\\python310\\lib\\site-packages (from alibi-detect) (4.38.0.dev0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.21.0 in d:\\program files\\python310\\lib\\site-packages (from alibi-detect) (2.28.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\program files\\python310\\lib\\site-packages (from alibi-detect) (4.4.0)\n",
      "Requirement already satisfied: opencv-python<5.0.0,>=3.2.0 in d:\\program files\\python310\\lib\\site-packages (from alibi-detect) (4.9.0.80)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.16.2 in d:\\program files\\python310\\lib\\site-packages (from alibi-detect) (1.24.3)\n",
      "Requirement already satisfied: matplotlib<4.0.0,>=3.0.0 in d:\\program files\\python310\\lib\\site-packages (from alibi-detect) (3.7.1)\n",
      "Requirement already satisfied: pydantic<2.0.0,>=1.8.0 in d:\\program files\\python310\\lib\\site-packages (from alibi-detect) (1.10.14)\n",
      "Requirement already satisfied: Pillow<11.0.0,>=5.4.1 in d:\\program files\\python310\\lib\\site-packages (from alibi-detect) (9.5.0)\n",
      "Requirement already satisfied: pandas<3.0.0,>=1.0.0 in d:\\program files\\python310\\lib\\site-packages (from alibi-detect) (2.0.1)\n",
      "Requirement already satisfied: scikit-image<0.23,>=0.19 in d:\\program files\\python310\\lib\\site-packages (from alibi-detect) (0.22.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in d:\\program files\\python310\\lib\\site-packages (from matplotlib<4.0.0,>=3.0.0->alibi-detect) (1.4.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in d:\\program files\\python310\\lib\\site-packages (from matplotlib<4.0.0,>=3.0.0->alibi-detect) (2.8.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in d:\\program files\\python310\\lib\\site-packages (from matplotlib<4.0.0,>=3.0.0->alibi-detect) (1.0.7)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\program files\\python310\\lib\\site-packages (from matplotlib<4.0.0,>=3.0.0->alibi-detect) (0.11.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in d:\\program files\\python310\\lib\\site-packages (from matplotlib<4.0.0,>=3.0.0->alibi-detect) (3.0.9)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\program files\\python310\\lib\\site-packages (from matplotlib<4.0.0,>=3.0.0->alibi-detect) (23.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in d:\\program files\\python310\\lib\\site-packages (from matplotlib<4.0.0,>=3.0.0->alibi-detect) (4.39.4)\n",
      "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in d:\\program files\\python310\\lib\\site-packages (from numba!=0.54.0,<0.59.0,>=0.50.0->alibi-detect) (0.41.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\program files\\python310\\lib\\site-packages (from pandas<3.0.0,>=1.0.0->alibi-detect) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in d:\\program files\\python310\\lib\\site-packages (from pandas<3.0.0,>=1.0.0->alibi-detect) (2023.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\program files\\python310\\lib\\site-packages (from requests<3.0.0,>=2.21.0->alibi-detect) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\program files\\python310\\lib\\site-packages (from requests<3.0.0,>=2.21.0->alibi-detect) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in d:\\program files\\python310\\lib\\site-packages (from requests<3.0.0,>=2.21.0->alibi-detect) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\program files\\python310\\lib\\site-packages (from requests<3.0.0,>=2.21.0->alibi-detect) (1.26.13)\n",
      "Requirement already satisfied: imageio>=2.27 in d:\\program files\\python310\\lib\\site-packages (from scikit-image<0.23,>=0.19->alibi-detect) (2.31.1)\n",
      "Requirement already satisfied: networkx>=2.8 in d:\\program files\\python310\\lib\\site-packages (from scikit-image<0.23,>=0.19->alibi-detect) (3.0)\n",
      "Requirement already satisfied: lazy_loader>=0.3 in d:\\program files\\python310\\lib\\site-packages (from scikit-image<0.23,>=0.19->alibi-detect) (0.3)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in d:\\program files\\python310\\lib\\site-packages (from scikit-image<0.23,>=0.19->alibi-detect) (2024.2.12)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in d:\\program files\\python310\\lib\\site-packages (from scikit-learn<2.0.0,>=0.20.2->alibi-detect) (3.1.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in d:\\program files\\python310\\lib\\site-packages (from scikit-learn<2.0.0,>=0.20.2->alibi-detect) (1.2.0)\n",
      "Requirement already satisfied: colorama in d:\\program files\\python310\\lib\\site-packages (from tqdm<5.0.0,>=4.28.1->alibi-detect) (0.4.6)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in d:\\program files\\python310\\lib\\site-packages (from transformers<5.0.0,>=4.0.0->alibi-detect) (0.15.1)\n",
      "Requirement already satisfied: filelock in d:\\program files\\python310\\lib\\site-packages (from transformers<5.0.0,>=4.0.0->alibi-detect) (3.9.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in d:\\program files\\python310\\lib\\site-packages (from transformers<5.0.0,>=4.0.0->alibi-detect) (0.4.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in d:\\program files\\python310\\lib\\site-packages (from transformers<5.0.0,>=4.0.0->alibi-detect) (2023.6.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in d:\\program files\\python310\\lib\\site-packages (from transformers<5.0.0,>=4.0.0->alibi-detect) (0.20.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\program files\\python310\\lib\\site-packages (from transformers<5.0.0,>=4.0.0->alibi-detect) (6.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in d:\\program files\\python310\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers<5.0.0,>=4.0.0->alibi-detect) (2023.6.0)\n",
      "Requirement already satisfied: six>=1.5 in d:\\program files\\python310\\lib\\site-packages (from python-dateutil>=2.7->matplotlib<4.0.0,>=3.0.0->alibi-detect) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 24.0\n",
      "[notice] To update, run: D:\\Program Files\\Python310\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install alibi-detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "E7dD3Ihi4GF9"
   },
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "\n",
    "import os\n",
    "\n",
    "import random\n",
    "random.seed(SEED)\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(SEED)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from alibi_detect.cd import TabularDrift"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xJjXNMOqcHVJ"
   },
   "source": [
    "1.Evaluate your model from B1 on data from year 2022 and report the test R2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "fOUcXL5OXASY"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">03</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:35:48</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">206</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">165</span><span style=\"font-weight: bold\">}</span> - INFO - Experiment Tracking is turned off           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2024\u001b[0m-\u001b[1;36m03\u001b[0m-\u001b[1;36m13\u001b[0m \u001b[1;92m22:35:48\u001b[0m,\u001b[1;36m206\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m165\u001b[0m\u001b[1m}\u001b[0m - INFO - Experiment Tracking is turned off           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">03</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:35:48</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">216</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">340</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2024\u001b[0m-\u001b[1;36m03\u001b[0m-\u001b[1;36m13\u001b[0m \u001b[1;92m22:35:48\u001b[0m,\u001b[1;36m216\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m340\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022 R2: 0.41781363520246395\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('hdb_price_prediction.csv')\n",
    "\n",
    "# TODO: Enter your code here\n",
    "import pytorch_tabular\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# load model\n",
    "model = pytorch_tabular.tabular_model.TabularModel.load_model('b1')\n",
    "\n",
    "# load data\n",
    "test_data_2022 = df[df['year'] == 2022]\n",
    "\n",
    "# test data\n",
    "pred_2022 = model.predict(test_data_2022)\n",
    "r2_2022 = r2_score(test_data_2022['resale_price'], pred_2022['resale_price_prediction'])\n",
    "\n",
    "print(f\"2022 R2: {r2_2022}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gsbs0iMiaUy-"
   },
   "source": [
    "2.Evaluate your model from B1 on data from year 2023 and report the test R2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "B4FLRQfBaRS-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023 R2: 0.13473505427989907\n"
     ]
    }
   ],
   "source": [
    "# TODO: Enter your code here\n",
    "test_data_2023 = df[df['year'] == 2023]\n",
    "\n",
    "# test data\n",
    "pred_2023 = model.predict(test_data_2023)\n",
    "r2_2023 = r2_score(test_data_2023['resale_price'], pred_2023['resale_price_prediction'])\n",
    "\n",
    "print(f\"2023 R2: {r2_2023}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "11mU8sxcaSAP"
   },
   "source": [
    "3.Did model degradation occur for the deep learning model?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "nviGacm6aSlf"
   },
   "outputs": [],
   "source": [
    "# YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, the model degradation occurred. Because the R^2 score of year 2022 is 0.4178 and it of year 2023 is only 0.1347, which is much less than 1, indicating the model cannot predict the data in 2022 and 2023 well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KyiP8gBAcABD"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ruldtSTDcYzt"
   },
   "source": [
    "4.Model degradation could be caused by [various data distribution shifts](https://huyenchip.com/2022/02/07/data-distribution-shifts-and-monitoring.html#data-shift-types): covariate shift (features), label shift and/or concept drift (altered relationship between features and labels).\n",
    "There are various conflicting terminologies in the [literature](https://www.sciencedirect.com/science/article/pii/S0950705122002854#tbl1). Let’s stick to this reference for this assignment.\n",
    "\n",
    "> Using the **Alibi Detect** library, apply the **TabularDrift** function with the training data (year 2019 and before) used as the reference and **detect which features have drifted** in the 2023 test dataset. Before running the statistical tests, ensure you **sample 1000 data points** each from the train and test data. Do not use the whole train/test data. (Hint: use this example as a guide https://docs.seldon.io/projects/alibi-detect/en/stable/examples/cd_chi2ks_adult.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "nGbdZc3ocYbB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drift? Yes!\n",
      "month -- Drift? No! -- Chi2 0.000 -- p-value 1.000\n",
      "town -- Drift? Yes! -- Chi2 667.474 -- p-value 0.000\n",
      "flat_model_type -- Drift? Yes! -- Chi2 77.586 -- p-value 0.000\n",
      "storey_range -- Drift? Yes! -- Chi2 38.800 -- p-value 0.001\n",
      "dist_to_nearest_stn -- Drift? No! -- K-S 0.055 -- p-value 0.094\n",
      "dist_to_dhoby -- Drift? Yes! -- K-S 0.218 -- p-value 0.000\n",
      "degree_centrality -- Drift? No! -- K-S 0.029 -- p-value 0.783\n",
      "eigenvector_centrality -- Drift? Yes! -- K-S 0.195 -- p-value 0.000\n",
      "remaining_lease_years -- Drift? Yes! -- K-S 0.271 -- p-value 0.000\n",
      "floor_area_sqm -- Drift? Yes! -- K-S 0.134 -- p-value 0.000\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "# load data\n",
    "train_data = df[df['year'] <= 2019]\n",
    "test_data = df[df['year'] == 2023]\n",
    "\n",
    "# set sample number\n",
    "n_ref = 1000\n",
    "n_test = 1000\n",
    "\n",
    "# sample data\n",
    "ref_data, test_data = train_data[:n_ref], test_data[:n_test]\n",
    "cat_embed_cols = ['month', 'town', 'flat_model_type', 'storey_range']\n",
    "continuous_cols = ['dist_to_nearest_stn', 'dist_to_dhoby', 'degree_centrality', 'eigenvector_centrality', 'remaining_lease_years', 'floor_area_sqm']\n",
    "target = ['resale_price']\n",
    "\n",
    "# define feature names and category map\n",
    "feature_names = cat_embed_cols + continuous_cols\n",
    "category_map = {\n",
    "    0: df['month'].unique().tolist(),\n",
    "    1: df['town'].unique().tolist(),\n",
    "    2: df['flat_model_type'].unique().tolist(),\n",
    "    3: df['storey_range'].unique().tolist(),\n",
    "}\n",
    "\n",
    "# set training and test data\n",
    "X_train = train_data[:n_ref]\n",
    "X_test = test_data[:n_test]\n",
    "X_ref = X_train[cat_embed_cols + continuous_cols].values\n",
    "X_test = X_test[cat_embed_cols + continuous_cols].values\n",
    "\n",
    "# define TabularDrift\n",
    "categories_per_feature = {f: None for f in list(category_map.keys())}\n",
    "cd = TabularDrift(X_ref, p_val=.05, categories_per_feature=categories_per_feature)\n",
    "\n",
    "# give predictions\n",
    "preds = cd.predict(X_test)\n",
    "labels = ['No!', 'Yes!']\n",
    "print('Drift? {}'.format(labels[preds['data']['is_drift']]))\n",
    "\n",
    "# detect drifting\n",
    "fpreds = cd.predict(X_test, drift_type='feature')\n",
    "for f in range(cd.n_features):\n",
    "    stat = 'Chi2' if f in list(categories_per_feature.keys()) else 'K-S'\n",
    "    fname = feature_names[f]\n",
    "    is_drift = fpreds['data']['is_drift'][f]\n",
    "    stat_val, p_val = fpreds['data']['distance'][f], fpreds['data']['p_val'][f]\n",
    "    print(f'{fname} -- Drift? {labels[is_drift]} -- {stat} {stat_val:.3f} -- p-value {p_val:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xmj3qq3PkJUf"
   },
   "source": [
    "5.Assuming that the flurry of housing measures have made an impact on the relationship between all the features and resale_price (i.e. P(Y|X) changes), which type of data distribution shift possibly led to model degradation?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "5UOsX4JqkZ9S"
   },
   "outputs": [],
   "source": [
    "# YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concept drift possibly led to model degradation. Since the input features X do not affect by housing measures, P(X) remains the same. At the mean time, because housing measures have made an impact on the relationship between all the features and resale_price, which leads to the change of P(Y|X). Therefore, it results in concept drift by definition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DM2OoOJdkZj1"
   },
   "source": [
    "6.From your analysis via TabularDrift, which features contribute to this shift?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "V3licBjskdLL"
   },
   "outputs": [],
   "source": [
    "# YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contributing features: town, flat_model_type, storey_range, dist_to_dhoby, eigenvector_centrality, remaining_lease_years, floor_area_sqm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yB3fSvKskhEJ"
   },
   "source": [
    "7.Suggest 1 way to address model degradation and implement it, showing improved test R2 for year 2023.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I use all data from 2017 to 2022 to train the model. But in order to put more importance on the more recent data, I give more proportion of the data on more recent years and give less on less recent years. Here I put all data in 2022, 80% of the data in 2021, 60% of the data in 2020, 40% of the data in 2019, 20% of the data in 2018, 10% of the data in 2017 into the dataset. Therfore, \n",
    "It enables the model to leverage both past context and present dynamics.\n",
    "\n",
    "After that, I split the dataset such that 90% of the data is used for training and 10% of the data is used for validation. Finally, we use the trained model to do prediction on 2023's data. The R^2 score is about 0.7038, which is improved a lot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "EqFinZObcYXu"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">03</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:35:50</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">666</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">140</span><span style=\"font-weight: bold\">}</span> - INFO - Experiment Tracking is turned off           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2024\u001b[0m-\u001b[1;36m03\u001b[0m-\u001b[1;36m13\u001b[0m \u001b[1;92m22:35:50\u001b[0m,\u001b[1;36m666\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m140\u001b[0m\u001b[1m}\u001b[0m - INFO - Experiment Tracking is turned off           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">03</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:35:50</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">803</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">524</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2024\u001b[0m-\u001b[1;36m03\u001b[0m-\u001b[1;36m13\u001b[0m \u001b[1;92m22:35:50\u001b[0m,\u001b[1;36m803\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m524\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">03</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:35:50</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">842</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:499</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2024\u001b[0m-\u001b[1;36m03\u001b[0m-\u001b[1;36m13\u001b[0m \u001b[1;92m22:35:50\u001b[0m,\u001b[1;36m842\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:499\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">03</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:35:50</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">967</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">574</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model: CategoryEmbeddingModel \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2024\u001b[0m-\u001b[1;36m03\u001b[0m-\u001b[1;36m13\u001b[0m \u001b[1;92m22:35:50\u001b[0m,\u001b[1;36m967\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m574\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model: CategoryEmbeddingModel \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">03</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:35:51</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">024</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">340</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2024\u001b[0m-\u001b[1;36m03\u001b[0m-\u001b[1;36m13\u001b[0m \u001b[1;92m22:35:51\u001b[0m,\u001b[1;36m024\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m340\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">03</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:35:51</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">088</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">630</span><span style=\"font-weight: bold\">}</span> - INFO - Auto LR Find Started                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2024\u001b[0m-\u001b[1;36m03\u001b[0m-\u001b[1;36m13\u001b[0m \u001b[1;92m22:35:51\u001b[0m,\u001b[1;36m088\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m630\u001b[0m\u001b[1m}\u001b[0m - INFO - Auto LR Find Started                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 4060 Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "D:\\Program Files\\Python310\\lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:639: Checkpoint directory E:\\git\\SC4001\\Programming Assignment\\saved_models exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "D:\\Program Files\\Python310\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "D:\\Program Files\\Python310\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d400b523abf8418eb338d5b06ecec32f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best initial lr:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=100` reached.\n",
      "Learning rate set to 0.6918309709189363\n",
      "Restoring states from the checkpoint path at E:\\git\\SC4001\\Programming Assignment\\.lr_find_86457976-9887-486d-883e-9f737d40f4dd.ckpt\n",
      "Restored all states from the checkpoint at E:\\git\\SC4001\\Programming Assignment\\.lr_find_86457976-9887-486d-883e-9f737d40f4dd.ckpt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">03</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:36:19</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">993</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">643</span><span style=\"font-weight: bold\">}</span> - INFO - Suggested LR: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6918309709189363</span>. For plot  \n",
       "and detailed analysis, use `find_learning_rate` method.                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2024\u001b[0m-\u001b[1;36m03\u001b[0m-\u001b[1;36m13\u001b[0m \u001b[1;92m22:36:19\u001b[0m,\u001b[1;36m993\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m643\u001b[0m\u001b[1m}\u001b[0m - INFO - Suggested LR: \u001b[1;36m0.6918309709189363\u001b[0m. For plot  \n",
       "and detailed analysis, use `find_learning_rate` method.                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">03</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:36:19</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">997</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">652</span><span style=\"font-weight: bold\">}</span> - INFO - Training Started                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2024\u001b[0m-\u001b[1;36m03\u001b[0m-\u001b[1;36m13\u001b[0m \u001b[1;92m22:36:19\u001b[0m,\u001b[1;36m997\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m652\u001b[0m\u001b[1m}\u001b[0m - INFO - Training Started                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type                      </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ _backbone        │ CategoryEmbeddingBackbone │  3.0 K │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ _embedding_layer │ Embedding1dLayer          │  1.6 K │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ head             │ LinearHead                │     51 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ loss             │ MSELoss                   │      0 │\n",
       "└───┴──────────────────┴───────────────────────────┴────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType                     \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ _backbone        │ CategoryEmbeddingBackbone │  3.0 K │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ _embedding_layer │ Embedding1dLayer          │  1.6 K │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ head             │ LinearHead                │     51 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ loss             │ MSELoss                   │      0 │\n",
       "└───┴──────────────────┴───────────────────────────┴────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 4.6 K                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 4.6 K                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 0                                                                          \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 4.6 K                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 4.6 K                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 0                                                                          \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2e1a99dae1a4b8794c0e78950f71487",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">03</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:38:18</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">590</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">663</span><span style=\"font-weight: bold\">}</span> - INFO - Training the model completed                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2024\u001b[0m-\u001b[1;36m03\u001b[0m-\u001b[1;36m13\u001b[0m \u001b[1;92m22:38:18\u001b[0m,\u001b[1;36m590\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m663\u001b[0m\u001b[1m}\u001b[0m - INFO - Training the model completed                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">03</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:38:18</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">592</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1489</span><span style=\"font-weight: bold\">}</span> - INFO - Loading the best model                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2024\u001b[0m-\u001b[1;36m03\u001b[0m-\u001b[1;36m13\u001b[0m \u001b[1;92m22:38:18\u001b[0m,\u001b[1;36m592\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1489\u001b[0m\u001b[1m}\u001b[0m - INFO - Loading the best model                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023 R2: 0.7037734076617993\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "from pytorch_tabular import TabularModel\n",
    "from pytorch_tabular.models import CategoryEmbeddingModelConfig\n",
    "from pytorch_tabular.config import (\n",
    "    DataConfig,\n",
    "    OptimizerConfig,\n",
    "    TrainerConfig,\n",
    ")\n",
    "\n",
    "# load data and set proportion\n",
    "data_2017 = df[df['year'] == 2017]\n",
    "data_2018 = df[df['year'] == 2018]\n",
    "data_2019 = df[df['year'] == 2019]\n",
    "data_2020 = df[df['year'] == 2020]\n",
    "data_2021 = df[df['year'] == 2021]\n",
    "data_2022 = df[df['year'] == 2022]\n",
    "data_2017 = data_2017.sample(n=int(0.1 * len(data_2017)), random_state=42)\n",
    "data_2018 = data_2018.sample(n=int(0.2 * len(data_2018)), random_state=42)\n",
    "data_2019 = data_2019.sample(n=int(0.4 * len(data_2019)), random_state=42)\n",
    "data_2020 = data_2020.sample(n=int(0.6 * len(data_2020)), random_state=42)\n",
    "data_2021 = data_2021.sample(n=int(0.8 * len(data_2021)), random_state=42)\n",
    "\n",
    "# shuffle the  data\n",
    "data = pd.concat([data_2017, data_2018, data_2019, data_2020, data_2021, data_2022])\n",
    "data_shuffled = data.sample(frac=1, random_state=42)\n",
    "split_index = int(0.9 * len(data_shuffled))\n",
    "train_data = data_shuffled.iloc[:split_index]\n",
    "val_data = data_shuffled.iloc[split_index:]\n",
    "test_data = df[df['year'] == 2023]\n",
    "\n",
    "# define data\n",
    "data_config = DataConfig(\n",
    "    target=['resale_price'],\n",
    "    continuous_cols=['dist_to_nearest_stn', 'dist_to_dhoby', 'degree_centrality', 'eigenvector_centrality', 'remaining_lease_years', 'floor_area_sqm'],\n",
    "    categorical_cols=['month', 'town', 'flat_model_type', 'storey_range']\n",
    ")\n",
    "\n",
    "# define trainer\n",
    "trainer_config = TrainerConfig(\n",
    "    batch_size=1024,\n",
    "    max_epochs=50,\n",
    "    auto_lr_find=True  # to find an optimal lr\n",
    ")\n",
    "\n",
    "# define model\n",
    "model_config = CategoryEmbeddingModelConfig(\n",
    "    task='regression',\n",
    "    layers='50'\n",
    ")\n",
    "\n",
    "# define optimizer\n",
    "optimizer_config = OptimizerConfig(\n",
    "    optimizer='Adam'\n",
    ")\n",
    "\n",
    "# initialization\n",
    "model = TabularModel(\n",
    "    data_config=data_config,\n",
    "    model_config=model_config,\n",
    "    optimizer_config=optimizer_config,\n",
    "    trainer_config=trainer_config,\n",
    ")\n",
    "\n",
    "# train the model\n",
    "model.fit(train=train_data, validation=val_data, seed=SEED)\n",
    "\n",
    "pred = model.predict(test_data)\n",
    "r2 = r2_score(test_data['resale_price'], pred['resale_price_prediction'])\n",
    "\n",
    "print(f\"2023 R2: {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The R^2 score is about 0.7038 after using this method, which is so much larger than 0.1347."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wQG9hZvAaq5g"
   },
   "source": [
    "### Appendix A\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G_ARi2OxbDuZ"
   },
   "source": [
    "Here are our results from a linear regression model. We used StandardScaler for continuous variables and OneHotEncoder for categorical variables.\n",
    "\n",
    "While 2021 data can be predicted well, test R2 dropped rapidly for 2022 and 2023.\n",
    "\n",
    "| Training set | Test set | Test R2 |\n",
    "|--------------|----------|---------|\n",
    "| Year <= 2020 | 2021     | 0.76    |\n",
    "| Year <= 2020 | **2022**     | 0.41    |\n",
    "| Year <= 2020 | **2023**     | **0.10**   |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vmv91FqgbI8h"
   },
   "source": [
    "Similarly, a model trained on 2017 data can predict 2018-2021 well (with slight degradation in performance for 2021), but drops drastically in 2022 and 2023.\n",
    "\n",
    "| Training set | Test set | Test R2 |\n",
    "|--------------|----------|---------|\n",
    "| 2017         | 2018     | 0.90    |\n",
    "|              | 2019     | 0.89    |\n",
    "|              | 2020     | 0.87    |\n",
    "|              | 2021     | 0.72    |\n",
    "|              | **2022**     | **0.37**    |\n",
    "|              | **2023**     | **0.09**    |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ayKGs106bI6S"
   },
   "source": [
    "With the test set fixed at year 2021, training on data from 2017-2020 still works well on the test data, with minimal degradation. Training sets closer to year 2021 generally do better.\n",
    "\n",
    "| Training set | Test set | Test R2 |\n",
    "|--------------|----------|---------|\n",
    "| 2020         | 2021     | 0.81    |\n",
    "| 2019         | 2021     | 0.75    |\n",
    "| 2018         | 2021     | 0.73    |\n",
    "| 2017         | 2021     | 0.72    |"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNWUKTcEICJ0j/YcXkGkr53",
   "collapsed_sections": [
    "wQG9hZvAaq5g"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
